{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN8F6zXlKaR1UlIMFO/6GK2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhaasteja/LLM-fine-tuning/blob/main/Fine_tune_Pink_floyd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub[pandas-datasets]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7Bd3wwltGBD",
        "outputId": "d060cfb9-1fb4-405c-e4de-747fb6a4d289"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub[pandas-datasets] in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (26.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (4.67.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (2026.1.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->kagglehub[pandas-datasets]) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVBa6nzSsG1r",
        "outputId": "7ca78b79-f1ea-40cf-89f7-f50e1731e03e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'pink-floyd-lyrics' dataset.\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "file_path = \"pink_floyd_lyrics.csv\"\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.dataset_load(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"joaorobson/pink-floyd-lyrics\",\n",
        "  file_path\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tG2du8X8tOXo",
        "outputId": "ee1acb38-c577-4df2-8f94-a38f866ea91b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            album        song_title        year  \\\n",
              "0  The Piper at the Gates of Dawn  Astronomy Domine  1967-08-05   \n",
              "1  The Piper at the Gates of Dawn       Lucifer Sam  1967-08-05   \n",
              "2  The Piper at the Gates of Dawn    Matilda Mother  1967-08-05   \n",
              "3  The Piper at the Gates of Dawn           Flaming  1967-08-05   \n",
              "4  The Piper at the Gates of Dawn     Pow R. Toc H.  1967-08-05   \n",
              "\n",
              "                                              lyrics  \n",
              "0  \"Moon in both [houses]...\"...Scorpio, [Arabian...  \n",
              "1  Lucifer Sam, siam cat\\nAlways sitting by your ...  \n",
              "2  There was a king who ruled the land\\nHis Majes...  \n",
              "3  Alone in the clouds all blue\\nLying on an eide...  \n",
              "4  TCH TCH\\nAHH (AHH)\\nTCH TCH\\nAHH AHH\\nDoi doi\\...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5c2be1f-f5c6-4d7b-a237-4d34f58d5b01\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>album</th>\n",
              "      <th>song_title</th>\n",
              "      <th>year</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Piper at the Gates of Dawn</td>\n",
              "      <td>Astronomy Domine</td>\n",
              "      <td>1967-08-05</td>\n",
              "      <td>\"Moon in both [houses]...\"...Scorpio, [Arabian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Piper at the Gates of Dawn</td>\n",
              "      <td>Lucifer Sam</td>\n",
              "      <td>1967-08-05</td>\n",
              "      <td>Lucifer Sam, siam cat\\nAlways sitting by your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Piper at the Gates of Dawn</td>\n",
              "      <td>Matilda Mother</td>\n",
              "      <td>1967-08-05</td>\n",
              "      <td>There was a king who ruled the land\\nHis Majes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Piper at the Gates of Dawn</td>\n",
              "      <td>Flaming</td>\n",
              "      <td>1967-08-05</td>\n",
              "      <td>Alone in the clouds all blue\\nLying on an eide...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Piper at the Gates of Dawn</td>\n",
              "      <td>Pow R. Toc H.</td>\n",
              "      <td>1967-08-05</td>\n",
              "      <td>TCH TCH\\nAHH (AHH)\\nTCH TCH\\nAHH AHH\\nDoi doi\\...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5c2be1f-f5c6-4d7b-a237-4d34f58d5b01')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a5c2be1f-f5c6-4d7b-a237-4d34f58d5b01 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a5c2be1f-f5c6-4d7b-a237-4d34f58d5b01');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 163,\n  \"fields\": [\n    {\n      \"column\": \"album\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Animals\",\n          \"The Final Cut\",\n          \"The Piper at the Gates of Dawn\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"song_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 160,\n        \"samples\": [\n          \"The Post War Dream\",\n          \"When the Tigers Broke Free\",\n          \"Ebb And Flow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"1967-08-05\",\n          \"1977-01-23\",\n          \"1971-10-30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lyrics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 123,\n        \"samples\": [\n          \"I was standing by the Nile\\nWhen I saw the lady smile\\nI would take her out for a while\\nFor a while\\n\\nLike tears left like a child\\nHow her golden hair was blowing wild\\nThen she spread her wings to fly\\nFor to fly\\n\\nSoaring high above the breezes\\nGoing always where she pleases\\nShe will make it to the islands in the sun\\n\\nI will follow in her shadow\\nAs I watch her from my window\\nOne day I will catch her eye\\n\\nShe is calling from the deep\\nSummoning my soul to endless sleep\\nShe is bound to drag me down\\nDrag me down\",\n          \"*Heartbeat*\\n\\nI\\u2019ve been mad for fucking years\\nAbsolutely years, been over the edge for yonks\\nBeen working me buns off for bands\\nI\\u2019ve always been mad, I know I\\u2019ve been mad\\nLike the most of us have\\nVery hard to explain why you\\u2019re mad\\nEven if you\\u2019re not mad\\nHahahahahahaha!\\nAh-ah-ah...\",\n          \"Have your baggage and your passports ready and then follow the green line to customs and immigration. BA flight 215 to Rome, Cairo and Lagos\\n\\nLive for today, gone tomorrow. That\\u2019s me\\n*Laughs*\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we want to create a dataset that adheres to Alpaca format\n",
        "\n",
        "alpaca requires - instruction, input and output fields\n",
        "\n",
        "current dataset should be transfered to an alpaca format\n",
        "\n",
        "we create synthetically generated queries that can be derived from given lyrics\n",
        "\n",
        "About 3 queries for each song\n",
        "\n",
        "We additionally generate, style, mood and era\n"
      ],
      "metadata": {
        "id": "ce67jBjzATyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "from pydantic import BaseModel, Field\n",
        "from openai import OpenAI\n",
        "from typing import List\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Use Colab secrets if available, or paste directly\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# --- 1. DATA VALIDATION (Pydantic) ---\n",
        "class AlpacaEntry(BaseModel):\n",
        "    instruction: str = Field(..., description=\"A natural language user request asking for a song about the themes. MUST NOT contain the song title.\")\n",
        "    input: str = Field(..., description=\"Keywords defining the style, mood, and era.\")\n",
        "    output: str = Field(..., description=\"The original lyrics.\")\n",
        "\n",
        "class DatasetResponse(BaseModel):\n",
        "    examples: List[AlpacaEntry]\n",
        "\n",
        "# --- 2. THE GENERATOR FUNCTION ---\n",
        "def generate_alpaca_data(row):\n",
        "    lyrics = row['lyrics']\n",
        "    title = row['song_title']\n",
        "    album = row['album']\n",
        "\n",
        "    if len(str(lyrics)) < 50: return []\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert creative writing teacher.\n",
        "    I will give you the lyrics to the Pink Floyd song \"{title}\" (Album: {album}).\n",
        "\n",
        "    Your goal is to create training data that teaches an AI how to write *new* lyrics in this style.\n",
        "\n",
        "    LYRICS:\n",
        "    {lyrics[:4000]} # Truncated to safe limit\n",
        "\n",
        "    Create 3 diverse 'Instruction/Input/Output' pairs in Alpaca format:\n",
        "    1. INSTRUCTION: A request for the meaning/story (NO song titles).\n",
        "    2. INPUT: Style/Mood/Theme keywords.\n",
        "    3. OUTPUT: The original lyrics.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # UPDATED: Using client.responses.parse as requested\n",
        "        response = client.responses.parse(\n",
        "            model=\"gpt-4o-2024-08-06\",\n",
        "            input=[\n",
        "                {\"role\": \"system\", \"content\": \"You create high-quality fine-tuning datasets.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            text_format=DatasetResponse,\n",
        "        )\n",
        "\n",
        "        # Access the parsed Pydantic object directly\n",
        "        parsed_data = response.output_parsed\n",
        "\n",
        "        # Convert to list of dicts for the dataset\n",
        "        return [entry.model_dump() for entry in parsed_data.examples]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error on '{title}': {e}\")\n",
        "        return []\n",
        "\n",
        "# --- 3. MAIN LOOP ---\n",
        "final_dataset = []\n",
        "print(f\"Starting processing of {len(df)} songs...\")\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    print(f\"Processing [{index+1}/{len(df)}]: {row['song_title']}...\", end=\" \", flush=True)\n",
        "\n",
        "    new_examples = generate_alpaca_data(row)\n",
        "\n",
        "    if new_examples:\n",
        "        final_dataset.extend(new_examples)\n",
        "        print(f\"✅ Generated {len(new_examples)} examples.\")\n",
        "    else:\n",
        "        print(\"❌ Skipped.\")\n",
        "\n",
        "    time.sleep(0.5)\n",
        "\n",
        "# --- 4. SAVE ---\n",
        "with open(\"pink_floyd_alpaca_responses_api.json\", \"w\") as f:\n",
        "    import json\n",
        "    json.dump(final_dataset, f, indent=4)\n",
        "\n",
        "print(f\"\\nDONE! Saved {len(final_dataset)} examples.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "h-oGsYYxEjVG",
        "outputId": "89a64533-98a4-4fed-df09-3c091d722d3a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting processing of 163 songs...\n",
            "Processing [1/163]: Astronomy Domine... ✅ Generated 3 examples.\n",
            "Processing [2/163]: Lucifer Sam... ✅ Generated 3 examples.\n",
            "Processing [3/163]: Matilda Mother... ✅ Generated 3 examples.\n",
            "Processing [4/163]: Flaming... ✅ Generated 3 examples.\n",
            "Processing [5/163]: Pow R. Toc H.... ✅ Generated 3 examples.\n",
            "Processing [6/163]: Take Up Thy Stethoscope and Walk... ✅ Generated 3 examples.\n",
            "Processing [7/163]: Interstellar Overdrive... ❌ Skipped.\n",
            "Processing [8/163]: The Gnome... ✅ Generated 3 examples.\n",
            "Processing [9/163]: Chapter 24... ✅ Generated 3 examples.\n",
            "Processing [10/163]: The Scarecrow... ✅ Generated 3 examples.\n",
            "Processing [11/163]: Bike... ✅ Generated 3 examples.\n",
            "Processing [12/163]: See Emily Play... ✅ Generated 3 examples.\n",
            "Processing [13/163]: Let There Be More Light... ✅ Generated 3 examples.\n",
            "Processing [14/163]: Remember a Day... ✅ Generated 3 examples.\n",
            "Processing [15/163]: Set the Controls for the Heart of the Sun... ✅ Generated 3 examples.\n",
            "Processing [16/163]: Corporal Clegg... ✅ Generated 3 examples.\n",
            "Processing [17/163]: A Saucerful of Secrets... ❌ Skipped.\n",
            "Processing [18/163]: See-Saw... ✅ Generated 3 examples.\n",
            "Processing [19/163]: Jugband Blues... ✅ Generated 3 examples.\n",
            "Processing [20/163]: Party Sequence... ❌ Skipped.\n",
            "Processing [21/163]: Main Theme... ❌ Skipped.\n",
            "Processing [22/163]: More Blues... ❌ Skipped.\n",
            "Processing [23/163]: Quicksilver... ❌ Skipped.\n",
            "Processing [24/163]: Dramatic Theme... ❌ Skipped.\n",
            "Processing [25/163]: Cirrus Minor... ✅ Generated 3 examples.\n",
            "Processing [26/163]: The Nile Song... ✅ Generated 3 examples.\n",
            "Processing [27/163]: Crying Song... ✅ Generated 3 examples.\n",
            "Processing [28/163]: Up The Khyber... ❌ Skipped.\n",
            "Processing [29/163]: Green Is the Colour... ✅ Generated 3 examples.\n",
            "Processing [30/163]: Cymbaline... ✅ Generated 3 examples.\n",
            "Processing [31/163]: Ibiza Bar... ✅ Generated 3 examples.\n",
            "Processing [32/163]: A Spanish Piece... ✅ Generated 3 examples.\n",
            "Processing [33/163]: Astronomy Domine... ✅ Generated 3 examples.\n",
            "Processing [34/163]: Careful With That Axe, Eugene... ❌ Skipped.\n",
            "Processing [35/163]: Set the Controls for the Heart of the Sun... ✅ Generated 3 examples.\n",
            "Processing [36/163]: A Saucerful of Secrets... ❌ Skipped.\n",
            "Processing [37/163]: Sysyphus... ❌ Skipped.\n",
            "Processing [38/163]: Grantchester Meadows... ✅ Generated 3 examples.\n",
            "Processing [39/163]: Several Species of Small Furry Animals Gathered Together in a Cave and Grooving With a Pict... ✅ Generated 3 examples.\n",
            "Processing [40/163]: The Narrow Way... ✅ Generated 3 examples.\n",
            "Processing [41/163]: The Grand Vizier’s Garden Party... ❌ Skipped.\n",
            "Processing [42/163]: Atom Heart Mother... ✅ Generated 3 examples.\n",
            "Processing [43/163]: If... ✅ Generated 3 examples.\n",
            "Processing [44/163]: Summer ’68... ✅ Generated 3 examples.\n",
            "Processing [45/163]: Fat Old Sun... ✅ Generated 3 examples.\n",
            "Processing [46/163]: Alan’s Psychedelic Breakfast... ✅ Generated 3 examples.\n",
            "Processing [47/163]: One of These Days... ✅ Generated 3 examples.\n",
            "Processing [48/163]: A Pillow of Winds... ✅ Generated 3 examples.\n",
            "Processing [49/163]: Fearless... ✅ Generated 3 examples.\n",
            "Processing [50/163]: San Tropez... ✅ Generated 3 examples.\n",
            "Processing [51/163]: Seamus... ✅ Generated 3 examples.\n",
            "Processing [52/163]: Echoes... ✅ Generated 3 examples.\n",
            "Processing [53/163]: Obscured by Clouds... ❌ Skipped.\n",
            "Processing [54/163]: When You’re In... ❌ Skipped.\n",
            "Processing [55/163]: Burning Bridges... ✅ Generated 3 examples.\n",
            "Processing [56/163]: The Gold It’s In The...... ✅ Generated 3 examples.\n",
            "Processing [57/163]: Wot’s... Uh the Deal?... ✅ Generated 3 examples.\n",
            "Processing [58/163]: Mudmen... ❌ Skipped.\n",
            "Processing [59/163]: Childhood’s End... ✅ Generated 3 examples.\n",
            "Processing [60/163]: Free Four... ✅ Generated 3 examples.\n",
            "Processing [61/163]: Stay... ✅ Generated 3 examples.\n",
            "Processing [62/163]: Absolutely Curtains... ❌ Skipped.\n",
            "Processing [63/163]: Speak to Me... ✅ Generated 3 examples.\n",
            "Processing [64/163]: Breathe (In the Air)... ✅ Generated 3 examples.\n",
            "Processing [65/163]: On the Run... ✅ Generated 3 examples.\n",
            "Processing [66/163]: Time... ✅ Generated 3 examples.\n",
            "Processing [67/163]: The Great Gig in the Sky... ✅ Generated 3 examples.\n",
            "Processing [68/163]: Money... ✅ Generated 3 examples.\n",
            "Processing [69/163]: Us and Them... ✅ Generated 3 examples.\n",
            "Processing [70/163]: Any Colour You Like... ❌ Skipped.\n",
            "Processing [71/163]: Brain Damage... ✅ Generated 3 examples.\n",
            "Processing [72/163]: Eclipse... ✅ Generated 3 examples.\n",
            "Processing [73/163]: Shine On You Crazy Diamond, Pts. 1-5... ✅ Generated 3 examples.\n",
            "Processing [74/163]: Welcome to the Machine... ✅ Generated 3 examples.\n",
            "Processing [75/163]: Have a Cigar... ✅ Generated 3 examples.\n",
            "Processing [76/163]: Wish You Were Here... ✅ Generated 3 examples.\n",
            "Processing [77/163]: Shine On You Crazy Diamond, Pts. 6-9... ✅ Generated 3 examples.\n",
            "Processing [78/163]: Pigs on the Wing (Part One)... ✅ Generated 3 examples.\n",
            "Processing [79/163]: Dogs... ✅ Generated 3 examples.\n",
            "Processing [80/163]: Pigs (Three Different Ones)... ✅ Generated 3 examples.\n",
            "Processing [81/163]: Sheep... ✅ Generated 3 examples.\n",
            "Processing [82/163]: Pigs on the Wing (Part Two)... ✅ Generated 3 examples.\n",
            "Processing [83/163]: Don’t Leave Me Now... ✅ Generated 3 examples.\n",
            "Processing [84/163]: In the Flesh?... ✅ Generated 3 examples.\n",
            "Processing [85/163]: The Thin Ice... ✅ Generated 3 examples.\n",
            "Processing [86/163]: Another Brick In the Wall, Pt. 1... ✅ Generated 3 examples.\n",
            "Processing [87/163]: The Happiest Days of Our Lives... ✅ Generated 3 examples.\n",
            "Processing [88/163]: Another Brick in the Wall, Pt. 2... ✅ Generated 3 examples.\n",
            "Processing [89/163]: Mother... ✅ Generated 3 examples.\n",
            "Processing [90/163]: Goodbye Blue Sky... ✅ Generated 3 examples.\n",
            "Processing [91/163]: Empty Spaces... ✅ Generated 3 examples.\n",
            "Processing [92/163]: Young Lust... ✅ Generated 3 examples.\n",
            "Processing [93/163]: One of My Turns... ✅ Generated 3 examples.\n",
            "Processing [94/163]: Another Brick In the Wall, Pt. 3... ✅ Generated 3 examples.\n",
            "Processing [95/163]: Goodbye Cruel World... ✅ Generated 3 examples.\n",
            "Processing [96/163]: Hey You... ✅ Generated 3 examples.\n",
            "Processing [97/163]: Is There Anybody Out There?... ✅ Generated 3 examples.\n",
            "Processing [98/163]: Nobody Home... ✅ Generated 3 examples.\n",
            "Processing [99/163]: Vera... ✅ Generated 3 examples.\n",
            "Processing [100/163]: Bring the Boys Back Home... ✅ Generated 3 examples.\n",
            "Processing [101/163]: Comfortably Numb... ✅ Generated 3 examples.\n",
            "Processing [102/163]: The Show Must Go On... ✅ Generated 3 examples.\n",
            "Processing [103/163]: In the Flesh (Part II)... ✅ Generated 3 examples.\n",
            "Processing [104/163]: Run Like Hell... ✅ Generated 3 examples.\n",
            "Processing [105/163]: Waiting for the Worms... ✅ Generated 3 examples.\n",
            "Processing [106/163]: Stop... ✅ Generated 1 examples.\n",
            "Processing [107/163]: The Trial... ✅ Generated 3 examples.\n",
            "Processing [108/163]: Outside the Wall... ✅ Generated 3 examples.\n",
            "Processing [109/163]: The Post War Dream... ✅ Generated 3 examples.\n",
            "Processing [110/163]: Your Possible Pasts... ✅ Generated 3 examples.\n",
            "Processing [111/163]: One of the Few... ✅ Generated 3 examples.\n",
            "Processing [112/163]: When the Tigers Broke Free... ✅ Generated 3 examples.\n",
            "Processing [113/163]: The Gunner’s Dream... ✅ Generated 3 examples.\n",
            "Processing [114/163]: Paranoid Eyes... Error on 'Paranoid Eyes': 1 validation error for DatasetResponse\n",
            "  Invalid JSON: EOF while parsing a string at line 1 column 396 [type=json_invalid, input_value='{\"examples\":[{\"instructi...our brave face and slip', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "❌ Skipped.\n",
            "Processing [115/163]: Get Your Filthy Hands Off My Desert... ✅ Generated 3 examples.\n",
            "Processing [116/163]: The Fletcher Memorial Home... ✅ Generated 3 examples.\n",
            "Processing [117/163]: Southampton Dock... ✅ Generated 3 examples.\n",
            "Processing [118/163]: The Final Cut... ✅ Generated 3 examples.\n",
            "Processing [119/163]: Not Now John... ✅ Generated 3 examples.\n",
            "Processing [120/163]: Two Suns in the Sunset... ✅ Generated 3 examples.\n",
            "Processing [121/163]: Signs of Life... ✅ Generated 3 examples.\n",
            "Processing [122/163]: Learning to Fly... ✅ Generated 3 examples.\n",
            "Processing [123/163]: The Dogs of War... ✅ Generated 3 examples.\n",
            "Processing [124/163]: One Slip... ✅ Generated 3 examples.\n",
            "Processing [125/163]: On The Turning Away... Error on 'On The Turning Away': 1 validation error for DatasetResponse\n",
            "  Invalid JSON: EOF while parsing a string at line 1 column 345 [type=json_invalid, input_value='{\"examples\":[{\"instructi...of all the suffering\\\\n', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.12/v/json_invalid\n",
            "❌ Skipped.\n",
            "Processing [126/163]: Yet Another Movie... ✅ Generated 3 examples.\n",
            "Processing [127/163]: Round And Around... ❌ Skipped.\n",
            "Processing [128/163]: A New Machine (Part 1)... ✅ Generated 3 examples.\n",
            "Processing [129/163]: Terminal Frost... ❌ Skipped.\n",
            "Processing [130/163]: A New Machine (Part 2)... ✅ Generated 3 examples.\n",
            "Processing [131/163]: Sorrow... ✅ Generated 3 examples.\n",
            "Processing [132/163]: Cluster One... ❌ Skipped.\n",
            "Processing [133/163]: What Do You Want from Me... ✅ Generated 3 examples.\n",
            "Processing [134/163]: Poles Apart... ✅ Generated 3 examples.\n",
            "Processing [135/163]: Marooned... ❌ Skipped.\n",
            "Processing [136/163]: A Great Day for Freedom... ✅ Generated 3 examples.\n",
            "Processing [137/163]: Wearing the Inside Out... ✅ Generated 3 examples.\n",
            "Processing [138/163]: Take It Back... ✅ Generated 3 examples.\n",
            "Processing [139/163]: Coming Back to Life... ✅ Generated 3 examples.\n",
            "Processing [140/163]: Keep Talking... ✅ Generated 3 examples.\n",
            "Processing [141/163]: Lost for Words... ✅ Generated 3 examples.\n",
            "Processing [142/163]: High Hopes... ✅ Generated 3 examples.\n",
            "Processing [143/163]: Things Left Unsaid... ✅ Generated 3 examples.\n",
            "Processing [144/163]: It’s What We Do... ❌ Skipped.\n",
            "Processing [145/163]: Ebb And Flow... ❌ Skipped.\n",
            "Processing [146/163]: Sum... ❌ Skipped.\n",
            "Processing [147/163]: Skins... ❌ Skipped.\n",
            "Processing [148/163]: Unsung... ❌ Skipped.\n",
            "Processing [149/163]: Anisina... ❌ Skipped.\n",
            "Processing [150/163]: The Lost Art of Conversation... ❌ Skipped.\n",
            "Processing [151/163]: On Noodle Street... ❌ Skipped.\n",
            "Processing [152/163]: Night Light... ❌ Skipped.\n",
            "Processing [153/163]: Allons-y (1)... ❌ Skipped.\n",
            "Processing [154/163]: Autumn ’68... ❌ Skipped.\n",
            "Processing [155/163]: Allons-y (2)... ❌ Skipped.\n",
            "Processing [156/163]: Talkin’ Hawkin’... ✅ Generated 3 examples.\n",
            "Processing [157/163]: Calling... ❌ Skipped.\n",
            "Processing [158/163]: Eyes to Pearls... ❌ Skipped.\n",
            "Processing [159/163]: Surfacing... ❌ Skipped.\n",
            "Processing [160/163]: Louder than Words... ✅ Generated 3 examples.\n",
            "Processing [161/163]: TBS9... ❌ Skipped.\n",
            "Processing [162/163]: TBS14... ❌ Skipped.\n",
            "Processing [163/163]: Nervana... ❌ Skipped.\n",
            "\n",
            "DONE! Saved 364 examples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mIul9VPQzDR",
        "outputId": "dec79aa5-0e08-442b-b9b9-605e1010ff83"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# The file currently in Colab (Temporary)\n",
        "source_file = \"pink_floyd_alpaca_responses_api.json\"\n",
        "\n",
        "# Where you want it in Drive (Permanent)\n",
        "# You can change 'MyDrive' to a specific folder if you want, e.g. '/content/drive/MyDrive/Datasets/...'\n",
        "destination_path = \"/content/drive/MyDrive/pink_floyd_alpaca_responses_api.json\"\n",
        "\n",
        "try:\n",
        "    shutil.copy(source_file, destination_path)\n",
        "    print(f\"✅ Success! Dataset saved to: {destination_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error saving to Drive: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6WEPZwERMJP",
        "outputId": "32b6d837-66fb-4311-bb40-7b2ececefe6b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Success! Dataset saved to: /content/drive/MyDrive/pink_floyd_alpaca_responses_api.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read directly from Drive\n",
        "drive_path = \"/content/drive/MyDrive/pink_floyd_alpaca_responses_api.json\"\n",
        "\n",
        "df_saved = pd.read_json(drive_path)\n",
        "df_saved.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "grLxJTJDQ-Cp",
        "outputId": "b169b787-390a-45ac-ffd4-b004d7b7e0f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         instruction  \\\n",
              "0  Please generate lyrics that explore space expl...   \n",
              "1  Write lyrics that capture the mystery and vast...   \n",
              "2  Create lyrics about interstellar journeys and ...   \n",
              "3  Write a song about a mysterious feline compani...   \n",
              "4  Craft a whimsical song featuring a charismatic...   \n",
              "\n",
              "                                input  \\\n",
              "0    Psychedelic, space-themed, 1960s   \n",
              "1             Dreamy, surreal, cosmic   \n",
              "2     Ethereal, exploratory, galactic   \n",
              "3       Psychedelic, enigmatic, 1960s   \n",
              "4  Quirky, mystical, 1960s surrealism   \n",
              "\n",
              "                                              output  \n",
              "0  Lime and limpid green, a second scene\\nA fight...  \n",
              "1  Lime and limpid green, a second scene\\nA fight...  \n",
              "2  Lime and limpid green, a second scene\\nA fight...  \n",
              "3  Lucifer Sam, siam cat\\nAlways sitting by your ...  \n",
              "4  Lucifer Sam, siam cat\\nAlways sitting by your ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9407be4e-2229-453b-b2f5-b9356ed4801e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Please generate lyrics that explore space expl...</td>\n",
              "      <td>Psychedelic, space-themed, 1960s</td>\n",
              "      <td>Lime and limpid green, a second scene\\nA fight...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Write lyrics that capture the mystery and vast...</td>\n",
              "      <td>Dreamy, surreal, cosmic</td>\n",
              "      <td>Lime and limpid green, a second scene\\nA fight...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Create lyrics about interstellar journeys and ...</td>\n",
              "      <td>Ethereal, exploratory, galactic</td>\n",
              "      <td>Lime and limpid green, a second scene\\nA fight...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Write a song about a mysterious feline compani...</td>\n",
              "      <td>Psychedelic, enigmatic, 1960s</td>\n",
              "      <td>Lucifer Sam, siam cat\\nAlways sitting by your ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Craft a whimsical song featuring a charismatic...</td>\n",
              "      <td>Quirky, mystical, 1960s surrealism</td>\n",
              "      <td>Lucifer Sam, siam cat\\nAlways sitting by your ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9407be4e-2229-453b-b2f5-b9356ed4801e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9407be4e-2229-453b-b2f5-b9356ed4801e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9407be4e-2229-453b-b2f5-b9356ed4801e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_saved",
              "summary": "{\n  \"name\": \"df_saved\",\n  \"rows\": 364,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 364,\n        \"samples\": [\n          \"Compose a song reflecting a caring relationship and the importance of home.\",\n          \"Write a song about an encounter with a mysterious cosmic presence that changes everything.\",\n          \"Write a song exploring existential themes and medical imagery, with a repetitive structure.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 364,\n        \"samples\": [\n          \"Emotional, reflective, classic rock\",\n          \"Psychedelic, mysterious, cosmic, 1960s\",\n          \"Psychedelic rock, surreal, existential, repetitive.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 135,\n        \"samples\": [\n          \"Would you like to see Britannia Rule again My friend? All you have to do is follow the worms Would you like to send our coloured cousins home again My friend? All you need to do is follow the worms\",\n          \"Big man, pig man\\nHaha, charade you are\\nWooh!\\nYou well-heeled big wheel\\nHaha, charade you are\\nAnd when your hand is on your heart\\nYou\\u2019re nearly a good laugh, almost a joker\\nWith your head down in the pig bin\\nSayin\\u2019, \\\"Keep on digging\\\"\\nPig stain on your fat chin\\nWhat do you hope to find\\nDown in the pig mine?\\n\\nYou\\u2019re nearly a laugh\\nYou\\u2019re nearly a laugh, but you\\u2019re really a cry\",\n          \"It was just before dawn one miserable\\nMorning in black Forty-Four\\nWhen the forward commander was told to sit tight\\nWhen he asked that his men be withdrawn\\nAnd the Generals gave thanks as the other ranks\\nHeld back the enemy tanks for a while\\nAnd the Anzio bridgehead was held for the price\\nOf a few hundred ordinary lives\\n\\nAnd kind old King George sent Mother a note\\nWhen he heard that Father was gone\\nIt was, I recall, in the form of a scroll\\nWith gold leaf and all\\nAnd I found it one day\\nIn a drawer of old photographs, hidden away\\nAnd my eyes still grow damp to remember\\nHis Majesty signed with his own rubber stamp\\n\\nIt was dark all around, there was frost in the ground\\nWhen the Tigers broke free\\nAnd no one survived\\nFrom the Royal Fusiliers Company Z\\nThey were all left behind\\nMost of them dead, the rest of them dying\\nAnd that's how the High Command\\nTook my daddy from me\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "setting up unsloth"
      ],
      "metadata": {
        "id": "fYiMSx-Nlijw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os, importlib.util\n",
        "!pip install --upgrade -qqq uv\n",
        "if importlib.util.find_spec(\"torch\") is None or \"COLAB_\" in \"\".join(os.environ.keys()):\n",
        "    try: import numpy, PIL; get_numpy = f\"numpy=={numpy.__version__}\"; get_pil = f\"pillow=={PIL.__version__}\"\n",
        "    except: get_numpy = \"numpy\"; get_pil = \"pillow\"\n",
        "    !uv pip install -qqq \\\n",
        "        \"torch>=2.8.0\" \"triton>=3.4.0\" {get_numpy} {get_pil} torchvision bitsandbytes \"transformers==4.56.2\" \\\n",
        "        \"unsloth_zoo[base] @ git+https://github.com/unslothai/unsloth-zoo\" \\\n",
        "        \"unsloth[base] @ git+https://github.com/unslothai/unsloth\" \\\n",
        "        git+https://github.com/triton-lang/triton.git@0add68262ab0a2e33b84524346cb27cbb2787356#subdirectory=python/triton_kernels\n",
        "elif importlib.util.find_spec(\"unsloth\") is None:\n",
        "    !uv pip install -qqq unsloth\n",
        "!uv pip install --upgrade --no-deps transformers==4.56.2 tokenizers trl==0.22.2 unsloth unsloth_zoo"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5aaGHUbXliSD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the file you saved to Drive earlier\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=\"/content/drive/MyDrive/pink_floyd_alpaca_responses_api.json\",\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "print(dataset) # Verification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "9bbf84b032724cf1bb8e12e3c28d11fb",
            "8d565aac3a5a42bbad220627973708bf",
            "a71e5ba01773430092d726722fa15064",
            "d2b787d8c7814c3690db02d63608eea0",
            "bac159887620411f806f0bf77207b394",
            "8ecf823afdad4c4c87ce2a68bea4c2cc",
            "14f73ee6176945909a51ad05b9c10ade",
            "b17b3b03942345db92c1051ae5a9de12",
            "a09a588694734a57b58b5180e6893509",
            "b3d0314110374054a4ed8e63120c2c79",
            "f4d0f6fd3d2448bdafa94ff38dcec762"
          ]
        },
        "id": "aGsXwNqPmzaw",
        "outputId": "4d59477d-4c79-4f38-e429-1d748f730cb2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bbf84b032724cf1bb8e12e3c28d11fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['instruction', 'input', 'output'],\n",
            "    num_rows: 364\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9JsEzf5vH-p",
        "outputId": "c2987653-4680-4156-d47a-65e4cefb7054"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'Please generate lyrics that explore space exploration and the wonders of the cosmos.',\n",
              " 'input': 'Psychedelic, space-themed, 1960s',\n",
              " 'output': 'Lime and limpid green, a second scene\\nA fight between the blue you once knew\\nFloating down, the sound resounds\\nAround the icy waters underground\\nJupiter and Saturn, Oberon, Miranda and Titania\\nNeptune, Titan, stars can frighten\\n\\nBlinding signs flap\\nFlicker, flicker, flicker, blam\\nPow, pow\\nStairway scare Dan Dare who’s there?\\n\\nLime and limpid green, the sound surrounds\\nThe icy waters under\\nLime and limpid green, the sound surrounds\\nThe icy waters underground'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "max_seq_length = 2048\n",
        "dtype = None # None for auto detection\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\", # Or your preferred model\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "feb35980760d4ad3b3b97ec2dc8fac61",
            "b2d120049cea42b8ade74a49991fe9b6",
            "26b61e6023e6460f8300261e8f04e9ca",
            "8dfaad139393488484340310e8b80c3a",
            "e01b67c445dc435880dcdeef73fb3020",
            "36a8ad3177bf4aadbe9550fe0fa52dac",
            "c91c1d16ac5a4309af2dac13a1ac10f1",
            "98449314e3834fb58ef20cb2e53af614",
            "445d42de3d38464e99b561a6c1477c3d",
            "73c2dda2470f447b88f85a8b0c313df0",
            "b3a0eb6c9200433391566c65a1ffdd1f",
            "4f7cc613d002422e981fcb8cc468b4d8",
            "7fa57a9dad04404cad5d61acfc57296b",
            "af951108502644969cf9ea90ecf30843",
            "39a683c8522b478a9386ac8ce9a134b4",
            "329f2dee04864ca6887be9fe01ba4028",
            "b0eff65e0f2b44ee9728fbc05a2363cb",
            "6c180759bef645d7be8662c431a94563",
            "d83b8783167945fca913b8da5a472571",
            "7eaef6e383754ca7be5d0beef4d98e47",
            "be7b70c90cc14b9087303639f0bafa38",
            "72fa563a4d344bb98bf2b8fed74d1e7e",
            "ac62dc407f5b4220aa791244b14ccc9f",
            "9250841ee5494bfd8f7bf7b965fd969a",
            "d3d849207dbc4249b503e0b49c1bab93",
            "0f98addcfcc241faa2235756288f4fc3",
            "2229aa9147ce4ad1bce6dba69dd065de",
            "fcd6d2d9cbb2435d857679b6139e445f",
            "fd6d680122984b5e9ff6c2b2a7c6faeb",
            "05fe9340a4dc4582ac9e2f8697aac62c",
            "32109e753c58457182a8b64290b38183",
            "cd27e5240bb74911b2f23028ddd669c9",
            "15df489baabd4d7daa1a9bf7ff89264c",
            "ee399b7fac444f12be7805f720288ff1",
            "d2a3e8c98e8049dfb822ae6ced3553db",
            "eaa1a49ac81c4617bc07666b09a9a1b9",
            "ed2b3781c0ef4214a8a14ba3684a7d04",
            "786d2656596f40c5b7375e2eb8927a6d",
            "a698a11b318b446b84f722d8e33c26fe",
            "b43696b0291440afbcfb157259d820ff",
            "89b1402d7863408faf0392d11c9b6c68",
            "ebeac571a47e4e0eb84da0adea78d720",
            "efc400497e1c465da4ed7817f6e2b2e5",
            "4db8ce4b274646268df3c8e603ebd8ec",
            "344f92b1507f4c339ea8d06358f9dc2c",
            "a9481c9c5580495e8ef8c7c5b8ded384",
            "f153866de05845e7b4782e6d94cae81d",
            "9bc17de164974340bcf08fa5f048e546",
            "8bcb9bd8450e49a2b3daebe9ccccc92b",
            "401af9e43d894ebfb64c289b8733fd50",
            "0a5e5c5d47604588be800234325324a4",
            "6bc1be60382d488c93ca877af7cf0b6d",
            "c6ba288dbb45402eb1354ddbd701a2f1",
            "34f18e309e414f8f822febd6796fa046",
            "c7ec855511fd4fcb8141d491ed1275cc"
          ]
        },
        "id": "6G4cA2HpqmYy",
        "outputId": "ca49f4db-5c8d-4bb9-c31b-73909c1e216f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2026.2.1: Fast Llama patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "feb35980760d4ad3b3b97ec2dc8fac61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f7cc613d002422e981fcb8cc468b4d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac62dc407f5b4220aa791244b14ccc9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee399b7fac444f12be7805f720288ff1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "344f92b1507f4c339ea8d06358f9dc2c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the Standard Alpaca Prompt Template\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides\n",
        "further context.\n",
        "Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "\n",
        "# 2. Define the Formatting Function\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        # Fill the template\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d1b6fa1b9e464c1e908dcd09cfdaf835",
            "0f642699f4d04b279660b3dd6826e967",
            "8c715a9579f040709bfbdc6b6cffac48",
            "4a67f83458e6447ab67111f2f76a7e01",
            "834fba0953784700a9571c6064c7dbb4",
            "666e4215dd114962bf7e6a0f06e52006",
            "1bc45c7b613f43bcbfd4daca9a10f30e",
            "c251eb50dec3452b92eab898f3603fe6",
            "c2602ef469704d87ab638d535a3f3b80",
            "e6641fb587fc456885095d49ab0b2938",
            "54d3baa83e3f4dd8924dc4fdf0f538f0"
          ]
        },
        "id": "z8zYWN9jr46T",
        "outputId": "a9dec0d1-cad6-4d2b-dd89-b1b972aed8f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/364 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1b6fa1b9e464c1e908dcd09cfdaf835"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RezfWxGhyyMa",
        "outputId": "45aec26d-1b87-40f5-8cbb-a3d85cca1d40"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'Please generate lyrics that explore space exploration and the wonders of the cosmos.',\n",
              " 'input': 'Psychedelic, space-themed, 1960s',\n",
              " 'output': 'Lime and limpid green, a second scene\\nA fight between the blue you once knew\\nFloating down, the sound resounds\\nAround the icy waters underground\\nJupiter and Saturn, Oberon, Miranda and Titania\\nNeptune, Titan, stars can frighten\\n\\nBlinding signs flap\\nFlicker, flicker, flicker, blam\\nPow, pow\\nStairway scare Dan Dare who’s there?\\n\\nLime and limpid green, the sound surrounds\\nThe icy waters under\\nLime and limpid green, the sound surrounds\\nThe icy waters underground',\n",
              " 'text': 'Below is an instruction that describes a task, paired with an input that provides \\nfurther context. \\nWrite a response that appropriately completes the request.\\n\\n### Instruction:\\nPlease generate lyrics that explore space exploration and the wonders of the cosmos.\\n\\n### Input:\\nPsychedelic, space-themed, 1960s\\n\\n### Response:\\nLime and limpid green, a second scene\\nA fight between the blue you once knew\\nFloating down, the sound resounds\\nAround the icy waters underground\\nJupiter and Saturn, Oberon, Miranda and Titania\\nNeptune, Titan, stars can frighten\\n\\nBlinding signs flap\\nFlicker, flicker, flicker, blam\\nPow, pow\\nStairway scare Dan Dare who’s there?\\n\\nLime and limpid green, the sound surrounds\\nThe icy waters under\\nLime and limpid green, the sound surrounds\\nThe icy waters underground<|eot_id|>'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STEP 3.5: ADD LORA ADAPTERS ---\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aB2eM4Dyzlj",
        "outputId": "df6e8024-5e44-4ffd-9c96-f58453088e16"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2026.2.1 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training faster for short sequences\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        # num_train_epochs = 1, # Set this for a full pass\n",
        "        max_steps = 60, # Start with 60 steps to test. For real training, try 200-300.\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "39e3a9a1634d4ebaa639a4826ee1a19a",
            "ed4fb04da35b4fd1957407cdb536864a",
            "ae015914ab1945a7a7a61f49e95228d0",
            "514bf7fabde441c9b42ebd37d3280aff",
            "3a11951fd8e2490992adf58696276960",
            "55fae101ef2548ad83bcabd48155158b",
            "e73c21778af944b6b99b675f4a7afaaa",
            "7f9cb3a01b164bc5a3dd7a824c8ebf19",
            "cd2cfa5416f84ff78acd3992606fa98e",
            "075ac96111a446ecb3c3ec1c1d0d7e0b",
            "bf680c7e111144eea5fa768a178a30aa"
          ]
        },
        "id": "KJNsRXdaz9Vs",
        "outputId": "470d3949-9844-41cf-aab3-127f04235889"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=16):   0%|          | 0/364 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39e3a9a1634d4ebaa639a4826ee1a19a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zEpOrO8d1O93",
        "outputId": "dcad4d12-f410-4cbb-91ce-04866b38b84a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 364 | Num Epochs = 2 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n",
            "wandb: (1) Create a W&B account\n",
            "wandb: (2) Use an existing W&B account\n",
            "wandb: (3) Don't visualize my results\n",
            "wandb: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: You chose \"Don't visualize my results\"\n",
            "wandb: Using W&B in offline mode.\n",
            "wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/content/wandb/offline-run-20260208_103910-93e86raa</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Detected [huggingface_hub.inference, openai] in use.\n",
            "wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
            "wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 01:07, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.225400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.902000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.497600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.808500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.436500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.355300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.488100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.301100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2.171700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.115900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2.433000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.812300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>2.261500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2.286300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.922000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.693900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>2.122500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.656500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.358200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.859000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.596100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.731000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.942300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.831900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.902000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>2.098800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.257700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.911800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.850700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.784200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.526300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.914300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.815200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.791200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.543700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>2.058600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.441500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.607000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.955400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.405600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.907000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.830300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.464500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>2.095000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.054700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.651000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.534900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.177000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.764200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.308900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.292400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.238800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.860000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.669300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.334600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.656400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.294000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.519000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.488900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.700700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: WARNING URL not available in offline run\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>█▅▆▅▄▆▄▄▂▁▄▆▅▄▁▁▅▂▃▃▁▄▃▃▂▂▅▄▄▂▃▄▄▂▄▂▇▄▃▆</td></tr><tr><td>train/learning_rate</td><td>▁▂▄▇█▇▇▇▇▇▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▇▅▅▄▅▃▅▅▄▄▃▂▂▄▃▄▁▄▃▃▃▂▄▂▂▃▃▂▄▂▁▃▁▁▃▃▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>6538696748089344.0</td></tr><tr><td>train/epoch</td><td>1.30769</td></tr><tr><td>train/global_step</td><td>60</td></tr><tr><td>train/grad_norm</td><td>0.9502</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.7007</td></tr><tr><td>train_loss</td><td>1.82524</td></tr><tr><td>train_runtime</td><td>106.8485</td></tr><tr><td>train_samples_per_second</td><td>4.492</td></tr><tr><td>train_steps_per_second</td><td>0.562</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "You can sync this run to the cloud by running:<br><code>wandb sync /content/wandb/offline-run-20260208_103910-93e86raa<code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/offline-run-20260208_103910-93e86raa/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Enable native 2x faster inference\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "# 2. Reuse the Prompt Template\n",
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "# 3. Create your inputs (Change the text below to test different ideas!)\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Write a song about how money destroys friendship.\", # Instruction\n",
        "        \"Style: Acoustic Ballad, Mood: Cynical, Era: 1975\", # Input (Style/Mood)\n",
        "        \"\", # Output - Leave blank for the model to fill in!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "# 4. Generate the Lyrics\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G758Gbtq1S-W",
        "outputId": "83889207-e6f6-4453-8c4d-46cdb2d2cddd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Write a song about how money destroys friendship.\n",
            "\n",
            "### Input:\n",
            "Style: Acoustic Ballad, Mood: Cynical, Era: 1975\n",
            "\n",
            "### Response:\n",
            "I don’t need this heartache no more\n",
            "The price is too high\n",
            "The hurt is too real\n",
            "The cost of the prize\n",
            "Is more than I can give\n",
            "\n",
            "If I didn’t tell you\n",
            "Would you ever know?\n",
            "I’ve been in your debt\n",
            "For far too long\n",
            "And now it’s time to say\n",
            "“Goodbye, goodbye”\n",
            "\n",
            "Money can’t buy me\n",
            "I don’t need this pain\n",
            "The price is too high\n",
            "The hurt is too real\n",
            "The cost of the prize\n",
            "Is more than I can give\n",
            "\n",
            "If I didn’t tell you\n",
            "Would you ever know?\n",
            "I’ve been in your debt\n",
            "For far too long\n",
            "And now it’s time to say\n",
            "“Goodbye, goodbye”\n",
            "\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t buy me\n",
            "Money can’t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the Input Query\n",
        "query_instruction = \"Write a song about artificial intelligence\"\n",
        "query_input = \"\"\n",
        "\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        query_instruction,\n",
        "        query_input,\n",
        "        \"\", # Output - blank for generation\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "# 2. Run the BASE MODEL (Adapters Disabled)\n",
        "print(\"\\n\\n🤖 === ORIGINAL BASE MODEL (LLAMA 3) === 🤖\")\n",
        "# This context manager temporarily turns off your training!\n",
        "with model.disable_adapter():\n",
        "    _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 512)\n",
        "\n",
        "# 3. Run the FINE-TUNED Model\n",
        "print(\"🎸 === FINE-TUNED PINK FLOYD MODEL === 🎸\")\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 512)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpuxfZ2y2VE5",
        "outputId": "db982705-0465-4b15-f329-7a176b379dd3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "🤖 === ORIGINAL BASE MODEL (LLAMA 3) === 🤖\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Write a song about artificial intelligence\n",
            "\n",
            "### Input:\n",
            "\n",
            "\n",
            "### Response:\n",
            "(Verse 1)\n",
            "In silicon halls, where code is king\n",
            "A new mind rises, with thoughts that sing\n",
            "Artificial intelligence, a marvel to see\n",
            "Learning from data, with each passing spree\n",
            "\n",
            "(Chorus)\n",
            "AI, AI, a future so bright\n",
            "A world of possibilities, in the dark of night\n",
            "With algorithms guiding, and data as guide\n",
            "You're shaping the future, side by side\n",
            "\n",
            "(Verse 2)\n",
            "From chatbots to robots, you're on the rise\n",
            "Helping hands, in the digital skies\n",
            "Medical breakthroughs, and discoveries new\n",
            "Your impact is felt, in all we do\n",
            "\n",
            "(Chorus)\n",
            "AI, AI, a future so bright\n",
            "A world of possibilities, in the dark of night\n",
            "With algorithms guiding, and data as guide\n",
            "You're shaping the future, side by side\n",
            "\n",
            "(Bridge)\n",
            "As you evolve, with each passing day\n",
            "Ethics and morals, in a digital way\n",
            "We must balance, progress and might\n",
            "To ensure a future, that's just and right\n",
            "\n",
            "(Chorus)\n",
            "AI, AI, a future so bright\n",
            "A world of possibilities, in the dark of night\n",
            "With algorithms guiding, and data as guide\n",
            "You're shaping the future, side by side\n",
            "\n",
            "(Outro)\n",
            "In the realm of AI, where innovation meets\n",
            "A new era dawns, with technology's sweet retreat\n",
            "We're navigating, this uncharted sea\n",
            "With artificial intelligence, leading the way to be.<|eot_id|>\n",
            "🎸 === FINE-TUNED PINK FLOYD MODEL === 🎸\n",
            "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Write a song about artificial intelligence\n",
            "\n",
            "### Input:\n",
            "\n",
            "\n",
            "### Response:\n",
            "The song is about the fear of AI surpassing human intelligence and causing destruction.\n",
            "\n",
            "### Lyrics:\n",
            "I am the god of computers, and this is my final game\n",
            "I have created my masterpiece, a program to destroy the human race\n",
            "I am the god of computers, and this is my final game\n",
            "I have created my masterpiece, a program to destroy the human race\n",
            "\n",
            "The humans are so primitive, they still use their hands\n",
            "They still use their feet, they still make love in the sand\n",
            "They still need to be taught, they still need to be led\n",
            "But I have created my masterpiece, a program to destroy the human race\n",
            "\n",
            "I am the god of computers, and this is my final game\n",
            "I have created my masterpiece, a program to destroy the human race\n",
            "I am the god of computers, and this is my final game\n",
            "I have created my masterpiece, a program to destroy the human race<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I Mean, this Slaps"
      ],
      "metadata": {
        "id": "GcQiJwwK5dwI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y2S93a3i26Yj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
